# Question Type: AI Governance

**Document:** [Copilot AUP](../../../../documentation/Microsoft%20Copilot%20%28individual%29/Copilot%20AUP.pdf)

| Question | Section Title | Exact Quote |
|----------|----------------|--------------|
| Does the vendor apply data governance and management practices to the collection and origin of data used in training, validation, and testing, and the original purpose if it involves personal data? | N/A | N/A |
| Does the vendor ensure that training and evaluation data sets are relevant, sufficiently representative and to the best extent possible, free of errors and complete in view of the intended purpose? Do the data sets have appropriate statistical properties, including, where applicable, as regards the persons or groups of persons in relation to whom the high-risk AI system is intended to be use? | N/A | N/A |
| Is vendor required to ensure data sets have, to the extent required by the intended purpose, the characteristics or elements that are particular to the specific geographical, contextual, behavioural or functional setting within which the high-risk AI system is intended to be used? | N/A | N/A |
| Is the vendor's processing of special categories of personal data necessary (i.e., the bias detection and correction cannot be effectively fulfilled by processing other data, including synthetic or anonymised data)? | N/A | N/A |
| Does the vendor delete special categories of personal data once bias has been corrected or personal data reached the end of the retention period, whichever comes first? | N/A | N/A |
| Do providers of high-risk AI systems have an accountability framework setting out the responsibilities of the management and other staff? | N/A | N/A |
| Does the importor refuse to place a high-risk AI system that it has sufficient reason to consider not in conformity with EU AI Act, or is falsified, or accompanied by falsified documentation? | N/A | N/A |
| Does the deployer of high-risk AI systems perform an assessment of the impact on fundamental rights that the use of such system may produce, including the measures to be taken in the case of the materialisation of those risks, including the arrangements for internal governance and complaint mechanisms? | N/A | N/A |
| Does the provider of general-purpose AI system perform model evaluation in accordance with standardised protocols and tools reflecting the state of the art, including conducting and documenting adversarial testing of the model with a view to identifying and mitigating systemic risks? | N/A | N/A |
| Does the AI actor develop AI that is consistent with human-centered values, such as fundamental freedoms, equality, fairness, rule of law, social justice, data protection and privacy, as well as consumer rights and commercial fairness? | N/A | N/A |